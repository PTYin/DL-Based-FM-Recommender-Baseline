tag: 'automotive_4'
dataset:
  decoder: 'libfm'
  num_workers: 4
  batch_size: 100  # batch size for training
  bipartite: False
  paths:
    train: '/home/share/yinxiangkun/libfm/data/rating/automotive/automotive.train.libfm'
    valid: '/home/share/yinxiangkun/libfm/data/rating/automotive/automotive.valid.libfm'
    test: '/home/share/yinxiangkun/libfm/data/rating/automotive/automotive.test.libfm'

model:
  name: 'DeepFM'
  loss_type: 'square_loss'  # ['square_loss', 'log_loss']
  optimizer: 'Adam'  # ['Adagrad', 'Adam', 'SGD', 'Momentum']
  learning_rate: 0.001
  epochs: 30
  steps_per_checkpoint: 500
  save: True  # save model or not
  model_path: '/home/share/yinxiangkun/saved/rating/DeepFM/'
  gpu: '0'  # gpu ID
  load: False
  evaluation: True

  hyper_params:
    activation_function: 'relu'  # ['relu', 'sigmoid', 'tanh', 'identity']
    batch_norm: True  # use batch_norm or not
    embedding_size: 4
    dropout_fm: [0.0, 0.0]  # dropout rate for FM
    dropout_deep: [0.0, 0.0]  # dropout rate for MLP
    deep_layers: [128, 128]  # size of layers in MLP model
    lambda: 0.001  # regularizer for deep layers and prediction layers

task: 'rating'  # ['rating', 'ranking']
